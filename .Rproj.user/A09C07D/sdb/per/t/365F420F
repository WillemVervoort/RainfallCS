{
    "contents" : "library(shiny)\nlibrary(RODBC)\nlibrary(oz)\n# for fancier plotting\nlibrary(ggplot2)\n\n\n# # connect to data source\n# db <- odbcConnect(\"testwillem\", uid=\"rver4657\", pwd=\"7564revrMySQL\")\n# \n# # # testing ODBC\n# # # find the names of the available tables\n# sqlTables(db)\n# #\n## Drop the different tables\n# sqlDrop(db,\"main_table\")\n# sqlDrop(db,\"regr_results\")\n# sqlDrop(db,\"regr_stats\")\n# odbcClose(db)\n\n## Clear the different tables\n#  sqlClear(db,\"main_table\")\n#  sqlClear(db,\"regr_results\")\n#  sqlClear(db,\"regr_stats\")\n#  odbcClose(db)\n\n\n# Source the dataripper script to get the data from the BOM site\n# This is adaption of Jason Lessels' bomDailyDataripper\nsource(\"dataripper.r\")\n# # this is using the multiplot function from the R cookbook\nsource(\"helper.r\")\n\nplot.fun <- function(Dates = DateInput(),\n                     Data=StationInput(),\n                     d.type=input$type) {\n  \n  # define labels\n  if (d.type==\"rain\") lab <- \"Rainfall\"; plot.t <- \"h\"\n  if (d.type==\"min_temp\") lab <- \"Minimum Temperature\"; plot.t <- \"l\"\n  if (d.type==\"max_temp\") lab <- \"Maximum Temperature\"; plot.t <- \"l\"\n  \n  # find begin and end dates from info\n  time1 <- match(as.Date(Dates$Startdate),as.Date(Data$Date))\n  time2 <- match(as.Date(Dates$Enddate),as.Date(Data$Date))\n\n  plot.df <- data.frame(Dates=Data$Date[time1:time2],\n                        values=Data[time1:time2,6])\n  # make the plot\nt.plot <-  ggplot(plot.df,aes(x=Dates,y=values)) +\n         geom_line(colour=\"blue\") +\n        geom_smooth(method=\"lm\", formula=y~x, colour=\"red\",\n                                       linetype=2, size=2) +\n  xlab(\"Dates\") + ylab(lab) + \n  ggtitle(paste(Data$stationNumber[1], \"for\", as.Date(Dates$Startdate), \"to\",\n                as.Date(Dates$Enddate)))\nprint(t.plot)\n}\n\n# mapping plot function\n# this function needs to be expanded to include frequnecy of analysis\n# in the size of the points.\nplot.map <- function(Data_in, background=oz.map, dtype=\"rain\") {\n  p1 <- ggplot(subset(background, border==\"coast\"), aes(long, lat))\n  p1 <- p1 + geom_path()\n  p1 <- p1 + coord_equal()\n  p1 <- p1 + ggtitle(\"Australia\")\n  #    p\n  #    p1 <- p +  geom_polygon(data=subset(oz.map,border=\"coast\"), aes(fill=state))\n  # Calculate the number of times a station is analysed\n  st.count <- count(Data_in$stations$station_ID)\n  for (i in 1:nrow(st.count)) {\n    Data_in$stations[Data_in$stations$station_ID %in% st.count$x[i],\"count\"] <- st.count$freq[i]\n  }\n  #neg slopes\n  st.count <- count(Data_in$neg.st$station_ID)\n  for (i in 1:nrow(st.count)) {\n    Data_in$neg.st[Data_in$neg.st$station_ID %in% st.count$x[i],\"count\"] <- st.count$freq[i]\n  }\n # pos slopes\n  st.count <- count(Data_in$pos.st$station_ID)\n  for (i in 1:nrow(st.count)) {\n    Data_in$pos.st[Data_in$pos.st$station_ID %in% st.count$x[i],\"count\"] <- st.count$freq[i]\n  }\n  \n  p1 <- p1 + geom_point(data=subset(Data_in$stations,Data_in$stations$data_type==dtype),\n                        aes(x=lon,y=lat),colour=\"black\",size=count)\n  p1 <- p1 + geom_point(data=subset(Data_in$neg.st,Data_in$neg.st$data_type==dtype),\n                        aes(x=lon,y=lat),colour=\"red\",size=count)\n  p1 <- p1 + geom_point(data=subset(Data_in$pos.st,Data_in$pos.st$data_type==dtype),\n                        aes(x=lon,y=lat),colour=\"blue\",size=count)\n  return(p1)\n  \n  \n}\n\n\n# histogram plotting function\nhist.fun <- function(Data_in, dtype=\"rain\") {\n\n  label <- ifelse(dtype==\"rain\",\"Rainfall\",\n                  ifelse(dtype==\"max_temp\",\"Maximum T\",\"Mimimum T\"))\n  units <- ifelse(dtype==\"rain\",\"mm/day\",\n                  ifelse(dtype==\"max_temp\",\"degree C/day\",\"degree C/day\"))\n  \n  \n  p2 <- ggplot(subset(Data_in,Data_in$data_type==dtype),\n               aes(x=slope))\n  p2 <- p2 + geom_histogram() +\n    xlab(paste(\"Change in\", units, \"for significant\",label,\n               \"slopes with p-value < 0.05\"))\n  return(p2)\n}\n  \n# histogram plotting function for times analysed\nhist.timefun <- function(Data_in, dtype=\"rain\") {\n  \n  Data_in$times <- round(as.numeric(difftime(Data_in$end_date,Data_in$start_date))/365,0)\n  \n  label <- ifelse(dtype==\"rain\",\"Rainfall\",\n                  ifelse(dtype==\"max_temp\",\"Maximum T\",\"Mimimum T\"))\n    \n  p3 <- ggplot(subset(Data_in,Data_in$data_type==dtype),\n               aes(x=times))\n  p3 <- p3 + geom_histogram() +\n    xlab(paste(\"Number of years analysed for significant\",label,\n               \"slopes with p-value < 0.05\"))\n  return(p3)\n}\n\n\n# This is the start of the server part\n# this gives the input and output\nshinyServer(function(input, output, session) {\n  \n  # here code that runs every time the app is visited\n\n  # create storage lists that are reactive\n  data <- reactiveValues()\n  name <- reactiveValues()\n  dates <- reactiveValues()\n#  dat <- reactiveValues()\n# find the station in the \n  StationOut <- reactive({\n    # find the station name in the station data set, now includes finding the state\n      name$name <- stations[grep(input$Station,stations$Site_name,\n                                 ignore.case=T),c(\"Site\",\"Site_name\",\"STA\",\"Lat\",\"Lon\")]\n     # This selects at least a station in the right state, but what to do if I have more than 1 station?\n      name$name2 <- name$name[grep(input$state,name$name$STA),]\n   # return(name$name2$Site)\n  })\n\n  output$choice <- renderUI({\n      selectInput('choice', label='Choose a Station',\n                  selected=StationOut()$Site[1], StationOut()$Site)\n  })\n\nStationInput <- reactive({\n      if (input$goButton == 0) \n        return()\n      # use dataripper to download data from BOM station\n      isolate(\n             data <- bomDailyObs(input$choice,observation=input$type))\n             \n       return(data)\n      })\n  \nDateInput <- reactive({\n   if (input$goButton == 0)  \n    return()\n   # this needs to read the dates and store them somewhere\n   begin <- input$dateRange[1]\n   end <- input$dateRange[2]\n   isolate(\n   if (is.character(StationInput())==T) {stop(\"no data available\")})\n   isolate(\n   if (begin >= min(StationInput()$Date)) {\n     dates$Startdate <- begin\n     dates$StartMsg <- paste(\"data analysis will start from\",begin)\n   } else {\n     dates$Startdate <- min(StationInput()$Date) #data$Date)\n     dates$StartMsg <- paste(\"the data only starts at\", min(StationInput()$Date))\n   })\n   \n   isolate({\n   if (end <= max(StationInput()$Date)) {\n     dates$Enddate <- end\n     dates$EndMsg <- paste(\"and the data ends at\",end)\n   } else {\n     dates$Enddate <- max(StationInput()$Date) #max(data$Date)\n     dates$EndMsg <- paste(\"and the data only runs till\", max(StationInput()$Date))\n   }\n   # define the begin and end rows to plot\n   temp <- match(as.Date(dates$Startdate),as.Date(StationInput()$Date))\n   temp2 <- match(as.Date(dates$Enddate),as.Date(StationInput()$Date))\n\n   ####################################################################\n   # Now run the regression using lm and store the data into a database\n   # need to work out what database (huge? or just small)\n   # current thinking is: just make a database locally, move later\n   # Probably can use AERDM from the Uni and therefore use MySQL\n   \n   \n   # define the regression data frame\n   df <- data.frame(time=1:nrow(StationInput()[temp:temp2,]), \n                    response=StationInput()[temp:temp2,6])\n   # run the regression (start simple with just linear)\n   lm.mod <- lm(response~time,df)\n   \n   # insert results into tables from database\n   #splitTime <- strsplit(as.character(Sys.time()),\" \")\n   #df_main[(nrow(df_main)+1),] <- \n   \n   # Find latitude and longitude for each station\n   Lat <- as.numeric(as.character(StationOut()$Lat[grep(input$choice,StationOut()$Site)]))\n   Lon <- as.numeric(as.character(StationOut()$Lon[grep(input$choice,StationOut()$Site)]))\n   \n   # Create input line for database  \n   test <- data.frame(station_ID = as.character(input$choice),\n                      Lat = Lat,\n                      Lon = Lon,\n                      data_type = input$type,\n                      timestamp = as.character(Sys.time()),\n                      start_date = as.character(dates$Startdate),\n                      end_date = as.character(dates$Enddate),\n                      comment = \"testing\",stringsAsFactors=F)\n#    main_table$station_ID = \n#    main_table$Lat = Lat;  line$Lon = Lon\n#    main_table$data_type = as.character(input$type)\n#    main_table$comment = as.character(\"testing\")\n#    # append database\n   db <- odbcConnect(\"testwillem\", uid=\"rver4657\", pwd=\"7564revrMySQL\", case=\"nochange\")\n  sqlSave(db,test,tablename=\"main_table\",\n          rownames=F,append=T)\n   \n   # sqlQuery(db,\"DESCRIBE main_table\")\n#   odbcClose(db)\n#    # coefficients and stats\n    mod.res <-  summary(lm.mod)$coefficients   \n    results <- data.frame(station_ID = as.character(input$choice),intercept = mod.res[1,1],\n            se_int = mod.res[1,2], p_value_int = mod.res[1,4],\n            slope = mod.res[2,1], se_slope = mod.res[2,2],\n            p_value_slope = mod.res[2,4], data_type=input$type,\n            comment=\"test\", stringsAsFactors=F)\n  # append database\n  try(sqlSave(db, results, tablename=\"regr_results\", \n            rownames=FALSE, append=T))\n# model statistics and summary\n    mod.sum <- summary(lm.mod)\n    fstat<-mod.sum$fstatistic\n    pv <-   pf(fstat[1], fstat[2], fstat[3], lower.tail=FALSE) \n    bias <- sum(residuals(lm.mod),na.rm=T)\n    stats <- data.frame(station_ID = as.character(input$choice), rmse = mod.sum$sigma, \n                      r_sq = mod.sum$adj.r.squared, p_value = pv, \n                      bias = bias, stat1 = mod.sum$r.squared, \n                      stat2 = fstat[1], stat3 = fstat[2], \n                      stat4 = fstat[3], stat5 = -9999, data_type=input$type,\n                      comment = \"test\", stringsAsFactors=F)\n    # append database\n    try(sqlSave(db, stats, tablename=\"regr_stats\", \n            rownames=FALSE, append=T))\n    \n    #bad <-   \n   # predict the regression line\n#    lm.line <- predict(lm.mod,\n#             new.data=data.frame(time=1:nrow(StationInput()[temp:temp2,]),\n#                                           response=rep(0,nrow(df))))\n#    dates$lm.line <- vector(length=nrow(df))\n#    dates$lm.line[as.numeric(names(lm.line))] <- lm.line\n   dates$lm.mod <- lm.mod\n    }) # close isolate()\n   # in here we need to write the output of the regression to the database\n   return(dates)\n })  \n\n\n  # ------------------------------------\n  # Start of output creation\n  #\n  # and create a plot\n output$plot <- renderPlot({\n    if (input$goButton == 0)\n      return() \n    # grab the data from StationInput\n    #data.plot <- StationInput()\n    # only run when submit is pushed??\n    isolate(plot.fun(Dates=DateInput(),\n                     Data=StationInput(),\n                     d.type=input$type)\n    )\n    \n    })\n\nextractData <- reactive({\n  if (input$goButton == 0)\n    return() \n    db <- odbcConnect(\"testwillem\", uid=\"rver4657\", pwd=\"7564revrMySQL\")\n    test <- sqlQuery(db,paste(\"SELECT station_ID, slope, p_value_slope, data_type FROM regr_results\"))\n  #    hist(dat$slope)\n  #  test <- test[test$p_value_slope < 0.05,]\n   st <- sqlQuery(db,paste(\"SELECT station_ID, lat, lon, start_date, end_date FROM main_table\"))\n  #    hist(dat$slope)\n  st.all <- cbind(st,test)\n  # close data base\n  odbcClose(db)\n  # select only significant slopes\n  st.out <- st.all[st.all$p_value_slope < 0.05,]\n  st.neg <- st.out[st.out$slope < 0,]\n  st.pos <- st.out[st.out$slope > 0,]\n  return(list(stations = st.all, sig.st = st.out, neg.st = st.neg, pos.st = st.pos))\n})\n\n\n\n# Make the map of Australia with analysed data\n# and a histogram\noutput$rain_map <- renderPlot({\n  if (input$goButton == 0)\n    return(\"\") \n  # \n  # only run when submit is pushed??\n    isolate({ \n      fig1 <- plot.map(Data_in = extractData(), dtype=\"rain\" )\n      fig2 <- hist.fun(Data_in=as.data.frame(extractData()$sig.st), dtype=\"rain\")\n      fig3 <- hist.timefun(Data_in=as.data.frame(extractData()$sig.st), dtype=\"rain\")\n      multiplot(fig1,fig2,fig3,cols=1)\n      })\n})\n\n# Make a map of Australia with pos and neg slopes\noutput$maxT_map <- renderPlot({\n  if (input$goButton == 0)\n    return(\"\") \n  # \n  # only run when submit is pushed??\n  \n  isolate({ \n    fig1 <-  plot.map(Data_in = extractData(), dtype=\"max_temp\" )\n    fig2 <- hist.fun(Data_in=as.data.frame(extractData()$sig.st), dtype=\"max_temp\")\n    fig3 <- hist.timefun(Data_in=as.data.frame(extractData()$sig.st), dtype=\"max_temp\")\n    multiplot(fig1,fig2,fig3,cols=1)\n  })\n})\n\noutput$minT_map <- renderPlot({\n  if (input$goButton == 0)\n    return(\"\") \n  # \n  # only run when submit is pushed??\n  isolate({ \n    fig1 <- plot.map(Data_in = extractData(), dtype=\"min_temp\" )\n    fig2 <- hist.fun(Data_in=as.data.frame(extractData()$sig.st), dtype=\"min_temp\")\n    fig3 <- hist.timefun(Data_in=as.data.frame(extractData()$sig.st), dtype=\"min_temp\")\n    multiplot(fig1,fig2,fig3,cols=1)\n    \n  })\n})\n\n\noutput$dateMsg <- renderPrint({\n  if (input$goButton == 0)\n    return(\"\")\n  # Display the dates that are available or chosen\n  isolate(cat(DateInput()$StartMsg,DateInput()$EndMsg, \"\\n\"))\n})\n\noutput$slope <- renderPrint({\n  if (input$goButton == 0) return(\"\")\n  isolate({\n  cat(\"The slope of the regression line is\",round(coef(DateInput()$lm.mod)[2],3),\n        \" with a p-value of\",round(summary(DateInput()$lm.mod)$coefficients[2,4],3),\".\")\n  cat(ifelse(summary(DateInput()$lm.mod)$coefficients[2,4]>0.05,\n         \" Statistically this means there is more than a 5% chance that this slope is similar to 0, \n         or we are not confident there is actually a trend.\",\n         paste(\" Statistically this means there is less than a 5% chance that this slope is similar to 0, \n         meaning we are quite confident there is a\",\n         ifelse(coef(DateInput()$lm.mod)[2]>=0,\"positive\",\"negative\"),\n         \"trend.\")))\n  })\n})\n\noutput$fitResults <- renderPrint({\n  if (input$goButton == 0) return(\"\")\n  isolate(\n    cat(\"The adj. r_squared of the line fit is\",round(summary(DateInput()$lm.mod)$adj.r.squared,2),\n      \" with an average residual value (RMSE) of\",round(summary(DateInput()$lm.mod)$sigma,3),\n      ifelse(input$type==\"rain\",\"mm\",\"degrees C\"),\".\"\n      ,\" In general terms, the closer the adj. r-squared is to 1 means a better fit of the model to the data.\")\n  )\n})\n\noutput$CautionComment <- renderPrint({\n  if (input$goButton == 0) return(\"\")\n  isolate(\n      cat(\"This analysis makes several assumptions, the most important one: that the trend in the data is linear! \n      Also, we are analysing the real data here, more common is to analyse the anomalies\"))\n})\n\n\n  output$testoutput1 <- renderPrint({\n     if (input$goButton == 0) \"\"\n      # this is just a test to see if everything works\n      \"for testing\" \n      # str(extractData()$sig.st)    \n      #DateInput()$lm.line[1:100]\n   })\n\n\n })\n\n#on.exit({\n  # first delete the tables (see http://stackoverflow.com/questions/23913616/rodbc-sqlsave-table-creation-problems)\n#  try(sqlDrop(db, sqtable=\"main_table\", errors = F), silent=T)\n#  try(sqlDrop(db, sqtable=\"regr_results\", errors = F), silent=T)\n#  try(sqlDrop(db, sqtable=\"regr_stats\", errors = F), silent=T)\n  # write data base tables back\n#  sqlSave(db, df_main, tablename=\"main_table\", rownames=FALSE,safer=F)\n#  sqlSave(db, df_regr_results, tablename=\"regr_results\", rownames=FALSE)\n#  sqlSave(db, df_regr_stats, tablename=\"regr_stats\", rownames=FALSE)\n  \n  # close the connection\n  \n # })\n\n\n",
    "created" : 1414753325522.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4264337582",
    "id" : "365F420F",
    "lastKnownWriteTime" : 1418296148,
    "path" : "~/GitHub/RainfallCS/server.R",
    "project_path" : "server.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}